#!/bin/python3

import math
# from re import L
import numpy as np

import gmsh
import sys

from pathlib import Path
import shutil
import os
from tqdm import tqdm
import procrustes as pr

from typing import Union


###########################   NN1   ###########################

def mesh_contour(coord: np.ndarray, mesh_file) -> np.ndarray:
    """Simple .mesh generation with Gmsh API from a given contour
    Returns the coordinates of inner vertices generated by GMSH

    :param np.ndarray coord: The coordinates of the contour
    :param string mesh_file: The name of the output .mesh file

    :return: Coordinates of inner vertices
    :rtype: np.ndarray
    """
    gmsh.initialize()

    # Print only gmsh warnings and errors
    gmsh.option.setNumber("General.Verbosity", 2)

    gmsh.model.add("polygon")

    # Number of vertices in contour
    nb_v_in_c = len(coord)

    # Constraint (h >> contour_lenght to avoid meshing (subdividing) of contours)
    h = 10

    # Vertices
    for i in range(nb_v_in_c):
        x = coord[i, 0]
        y = coord[i, 1]
        gmsh.model.geo.addPoint(x, y, 0, h, i)

    # Edges
    for i in range(nb_v_in_c):
        gmsh.model.geo.addLine(i, (i+1) % nb_v_in_c, i)

    gmsh.model.geo.addCurveLoop([i for i in range(nb_v_in_c)], 1)

    gmsh.model.geo.addPlaneSurface([1], 1)

    gmsh.model.geo.synchronize()

    # Meshing
    # gmsh.model.mesh.setAlgorithm(2, 1, 3) #Add non points
    gmsh.model.mesh.generate(2)

    # Coordinates of inner_vertices
    coord_inner_v = gmsh.model.mesh.getNodes()[1][len(
        coord)*3:]
   # Delete the third coordinates
    if len(coord_inner_v) > 0:
        coord_inner_v = np.delete(
            coord_inner_v, np.arange(-1, coord_inner_v.size, 3))

    gmsh.write(str(mesh_file))

    # # Open mesh in GUI
    if '-nopopup' not in sys.argv:
        gmsh.fltk.run()

    gmsh.model.remove()
    # gmsh.finalize()

    return coord_inner_v


def create_random_contour(nvert: int) -> np.ndarray:
    """Create a random polygonal contour with nvert vertices

    :param int nvert: The number of desired vertices

    :return: Vector of coordinates for the nvert vertices
    :rtype: np.ndarray
    """
    r = 1.
    rmin = 0.7
    theta = 0.
    x = y = 0.
    coord = np.ndarray((nvert, 2))

    for i in range(0, nvert):
        theta = (i + np.random.rand()) / nvert * 2 * math.pi
        r = np.random.rand() * (1 - rmin) + rmin
        x = r * math.cos(theta)
        y = r * math.sin(theta)

        coord[i, 0] = x
        coord[i, 1] = y

    return coord


def gen_database(Nc: int,  # Number of contour edges
                 # Dictionnary of requested polygons
                 # Request fomating dict({(ls,nb_of_polygons),(ls,nb_of_polygons)....})
                 requested_polygons: dict,
                 # Delete any previous files to start clean
                 # Data main folder
                 data_path: Path = Path("data"),
                 # Subfolders
                 meshes_folder: Path = Path("meshes"),
                 polygons_folder: Path = Path("polygons"),
                 # Label file
                 label_filename: Path = Path("labels"),
                 clean_data_dirs: bool = True) -> None:
    """Generates transformed contours and saves multiples output files
    Takes a dictionnary with numbers of requested polygons
    Request fomating : dict({(ls,nb_of_polygons),(ls,nb_of_polygons)....})


    Creates folders to store meshes and polygons
    Creates label file with two cols : filename, number of inner vertices
    Creates a file .dat for each polygon containing in one cols : (ls,x1,y1,x2,y2.....)^t
    Creates a file .mesh for each polygon generated by Gmsh

    Displays a simple progress bar with tqdm

    :param int Nc: Number of contour edges
    :param dict requested_polygons: Requested polygons
    :param Path data_path: main folder to store dataset
    :param Path meshes_folder: folder to store .mesh files
    :param Path polygons_folder:folder to store .dat files
    :param Path label_filename:Label file with
    :param bool clean_data_dirs: Delete any previous file and directories

    :return: Creates the output files in the desired folder
    :rtype:
    """
    print(f"Generating database for {Nc} vertices.")

    # Add polygons folder
    data_path = data_path / Path(str(Nc))

    # Delete any previous files to start clean
    if clean_data_dirs:
        shutil.rmtree(data_path, ignore_errors=True)

    # create tree
    try:
        os.makedirs(data_path)
    except FileExistsError:
        pass
    # data_path.mkdir(exist_ok=True)
    (data_path / polygons_folder).mkdir(exist_ok=True)
    (data_path / meshes_folder).mkdir(exist_ok=True)

    gmsh.initialize()

    # Create label file
    with open(data_path / label_filename, "w+") as label_file:
        # Header
        label_file.write("filename, N1\n")
        # Generate polygons, tqdm create a progress bar
        idx = 0
        for ls in sorted(requested_polygons.keys()):
            for _ in tqdm(range(requested_polygons[ls])):
                polygon_filename = Path(f"coord{ls}_{idx}.dat")

                # Creation of polygon
                coord = create_random_contour(Nc)
                # Normalisation
                pr.procrustes(coord)
                # Mesh polygon and get nb of inner vertices
                nb_inner_vert = len(mesh_contour(
                    coord, data_path / meshes_folder / polygon_filename.with_suffix(".mesh")))/2
                # Write label files
                label_file.write(f"{polygon_filename}, {nb_inner_vert}\n")

                # Write polygon file
                with open(data_path / polygons_folder / polygon_filename, "w+") as polygon_file:
                    polygon_file.write(str(ls)+"\n")
                    for i in coord:
                        polygon_file.write(str(i[0])+"\n")
                        polygon_file.write(str(i[1])+"\n")
                idx += 1
    gmsh.finalize()
    return


###########################   NN2   ###########################

def is_in_contour(x: float, y: float, coord: np.ndarray) -> bool:
    # Determine if the point is in the polygon.
    #
    # Args:
    #   x -- The x coordinates of point.
    #   y -- The y coordinates of point.
    #   coord -- a list of tuples [(x, y), (x, y), ...]
    #
    # Returns:
    #   True if the point is in the path or is a corner or on the boundary

    num = len(coord)
    j = num - 1
    c = False
    for i in range(num):
        if (x == coord[i][0]) and (y == coord[i][1]):
            # point is a corner
            return True
        if ((coord[i][1] > y) != (coord[j][1] > y)):
            slope = (x-coord[i][0])*(coord[j][1]-coord[i][1]) - \
                (coord[j][0]-coord[i][0])*(y-coord[i][1])
            if slope == 0:
                # point is on boundary
                return True
            if (slope < 0) != (coord[j][1] < coord[i][1]):
                c = not c
        j = i
    return c


def create_grid(coord: np.ndarray, ls: float) -> np.ndarray:
    """
    Creates uniform grided square arond the contour

    :param float ls: size of an edge inside the polygon

    :return: Coordinates of the grid
    :rtype: np.ndarray
    """
    # Grid scale factor
    Gscale_factor = 0.01
    Gscale = Gscale_factor * ls  # size of mesh grid
    nnodes = int(2/Gscale)  # number of nodes on the grid side
    grid = np.empty((0, 2))
    x = -Gscale*nnodes/2  # On commence en bas a gauche du grid
    y = -Gscale*nnodes/2
    for i in range(nnodes):
        for j in range(nnodes):
            if is_in_contour(x, y, coord):
                grid = np.append(grid, [x, y])  # NOT WORKING !!!!!
                print(grid.shape)

            x += Gscale
            # print(i,j)
            # print(grid[i+j,0],grid[i+j,1])
        x = -Gscale*nnodes/2
        y += Gscale

    print("grid =", grid)
    return grid


def score_of_node(node: np.ndarray, nodes: np.ndarray) -> float:
    '''Gives the score of a grid node

    :param np.ndarray node: the grid node considered
    :param np.ndarray nodes: the coordinates of the inner vertices

    :return: score of the node
    :rtype: float
    '''
    nb_nodes = nodes.size//2  # number of inner vertices
    dist = np.zeros(nb_nodes)
    for i in range(0, nb_nodes):
        dist[i] = math.sqrt((node[0]-nodes[2*i])**2 +
                            (node[1]-nodes[2*i+1])**2)
    return min(dist)


def calculate_score_array(grid: np.ndarray, coord_inner_v: np.ndarray) -> np.ndarray:
    """Computes the scores of each grid node

    :param np.ndarray grid: the grid node over the polygon
    :param np.ndarray coord_inner_v: the coordinates of the inner vertices

    :return: scores of all grid nodes in a vector
    :rtype: np.ndarray
    """
    nb_nodes = (grid.size)//2
    Scores = np.zeros(nb_nodes)
    for i in range(nb_nodes):
        Scores[i] = score_of_node(
            np.array([grid[i, 0], grid[i, 1]]), coord_inner_v)
    return Scores


def main():
    # gmsh.initialize()
    # Test one mesh
    # coord = create_random_contour(10)
    # pr.procrustes(coord)
    # mesh_contour(coord, "out.msh")
    # gmsh.finalize()

    # Gen database
    # request fomating dict({(ls,nb_of_polygons),(ls,nb_of_polygons)....})

    # request = dict({(1.0, 1)})
    # gen_database(6, request)
    # request = dict({(1.0, 12000)})
    # gen_database(6, request)
    # request = dict({(1.0, 1)})
    # gen_database(8, request)
    # request = dict({(1.0, 48000)})
    # gen_database(10, request)
    # request = dict({(1.0, 95000)})
    # gen_database(12, request)
    # request = dict({(1.0, 190000)})
    # gen_database(14, request)
    # request = dict({(1.0, 380000)})
    # gen_database(16, request)

    contour = create_random_contour(8)
    grid = create_grid(contour, 1.0)

    coord_inner_v = mesh_contour(contour, "out.mesh")
    print("coord_inner_v", coord_inner_v)
    scores = calculate_score_array(grid, coord_inner_v)

    return


if __name__ == "__main__":
    main()
